{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>118</td>\n",
       "      <td>127</td>\n",
       "      <td>134</td>\n",
       "      <td>139</td>\n",
       "      <td>143</td>\n",
       "      <td>146</td>\n",
       "      <td>150</td>\n",
       "      <td>153</td>\n",
       "      <td>...</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>204</td>\n",
       "      <td>203</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>155</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>149</td>\n",
       "      <td>128</td>\n",
       "      <td>87</td>\n",
       "      <td>94</td>\n",
       "      <td>163</td>\n",
       "      <td>175</td>\n",
       "      <td>103</td>\n",
       "      <td>135</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>202</td>\n",
       "      <td>201</td>\n",
       "      <td>200</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>195</td>\n",
       "      <td>194</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>235</td>\n",
       "      <td>234</td>\n",
       "      <td>233</td>\n",
       "      <td>231</td>\n",
       "      <td>230</td>\n",
       "      <td>226</td>\n",
       "      <td>225</td>\n",
       "      <td>222</td>\n",
       "      <td>229</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>164</td>\n",
       "      <td>167</td>\n",
       "      <td>170</td>\n",
       "      <td>172</td>\n",
       "      <td>176</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>108</td>\n",
       "      <td>133</td>\n",
       "      <td>163</td>\n",
       "      <td>157</td>\n",
       "      <td>163</td>\n",
       "      <td>164</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      3     107     118     127     134     139     143     146     150   \n",
       "1      6     155     157     156     156     156     157     156     158   \n",
       "2      2     187     188     188     187     187     186     187     188   \n",
       "3      2     211     211     212     212     211     210     211     210   \n",
       "4     13     164     167     170     172     176     179     180     184   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0     153  ...       207       207       207       207       206       206   \n",
       "1     158  ...        69       149       128        87        94       163   \n",
       "2     187  ...       202       201       200       199       198       199   \n",
       "3     210  ...       235       234       233       231       230       226   \n",
       "4     185  ...        92       105       105       108       133       163   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0       206       204       203       202  \n",
       "1       175       103       135       149  \n",
       "2       198       195       194       195  \n",
       "3       225       222       229       163  \n",
       "4       157       163       164       179  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../data/lab_6/sign_mnist_train.csv')\n",
    "test = pd.read_csv('../data/lab_6/sign_mnist_test.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27455, 785)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = train['label'].values\n",
    "unique_val = np.array(labels)\n",
    "np.unique(unique_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f64842212d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABCkAAAHSCAYAAADBm5EaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3df7RmdV0v8PdHRvxBKSAj6gze4RbZ5bpKaSLKfl3pKqA5aGi4tBBpTXk1f94Ks5X9ci1NzbS6FFdANK5iKDoahoSa664VyICo/FInRZkJmFFRu7nSyO/949ljh/GcM6d6nmd/z5zXa61nnb2/e59n3jzMefYz7/Pde1drLQAAAABju9fYAQAAAAASJQUAAADQCSUFAAAA0AUlBQAAANAFJQUAAADQBSUFAAAA0IV1YweYhSOOOKJt2rRp7BgAAADAPq699tovtNbWL7btgCwpNm3alO3bt48dAwAAANhHVX1uqW1O9wAAAAC6oKQAAAAAuqCkAAAAALqgpAAAAAC6oKQAAAAAuqCkAAAAALqgpAAAAAC6oKQAAAAAuqCkAAAAALqgpAAAAAC6oKQAAAAAuqCkAAAAALqgpAAAAAC6oKQAAAAAuqCkAAAAALqgpAAAAAC6oKQAAAAAuqCkAAAAALqgpAAAAAC6sG7sAAAAcKB4/qW3jR0hSfKGJx81dgSAfxczKQAAAIAuKCkAAACALigpAAAAgC64JgUAAN077R3XjR0hSXLJzxw3dgSAA5qZFAAAAEAXlBQAAABAF5QUAAAAQBeUFAAAAEAXlBQAAABAF5QUAAAAQBeUFAAAAEAXlBQAAABAF5QUAAAAQBeUFAAAAEAXlBQAAABAF5QUAAAAQBfWjR0AANaCJ1z66rEjJEn+8sm/MnYEAIAlmUkBAAAAdEFJAQAAAHRBSQEAAAB0QUkBAAAAdMGFMwEAAOjCHa+9ZewISZKHvOR7x46wZplJAQAAAHRBSQEAAAB0QUkBAAAAdGFmJUVVnV9Vu6vqhgVjr66qW6rq41V1aVUdumDbS6tqR1V9sqoev2D8pGFsR1WdPau8AAAAwLhmOZPiTUlO2mfsiiSPbK19X5JPJXlpklTVsUlOT/Jfh+/5X1V1UFUdlORPkpyc5NgkTx/2BQAAAA4wM7u7R2vtw1W1aZ+x9y9YvSrJacPyliRva619Pclnq2pHkuOHbTtaa59Jkqp627DvTbPKDSzu4gv27Rzn72fP/KuxIwAAADM05jUpnp3kfcPyhiS3Ldi2cxhbahwAAAA4wMxsJsVyquplSe5OctEUn3Nrkq1J8vCHP3xaTwsAAAecN75z99gRkiS/8JQHjx0B6MzcS4qqelaSJyY5sbXWhuFdSY5asNvGYSzLjN9Da+3cJOcmyebNm9ti+7C2XPNnPz12hCTJD/7ie8aOAMBIfvqSd40dIe857dSxIwDAis31dI+qOinJryZ5Umvtaws2bUtyelXdp6qOTnJMko8kuSbJMVV1dFUdnMnFNbfNMzMAAAAwHzObSVFVb03yk0mOqKqdSV6eyd087pPkiqpKkqtaa7/UWruxqt6eyQUx707y3NbavwzP87wklyc5KMn5rbUbZ5UZAAAAGM8s7+7x9EWGz1tm/1ckecUi45cluWyK0QAAgFXgfRd/YewIOflnjxg7AqwpY97dAwAAAOBblBQAAABAF5QUAAAAQBeUFAAAAEAXlBQAAABAF5QUAAAAQBdmdgtSAAAAOBDd+fq/HTtCkuTIF/zw2BGmTkkBwKLOvPSksSMkSS548l+NHQEAlnXNBbvHjpAfPPPBY0eAqXC6BwAAANAFJQUAAADQBad7AACrzhMvuWjsCHnvac8YOwIAHHDMpAAAAAC6oKQAAAAAuuB0D/7NPv+G08aOkCR5+PMvGTsCAAAAU2QmBQAAANAFJQUAAADQBSUFAAAA0AUlBQAAANCFNXPhzD3n/PnYEbL+Oc8cOwIAAAB0y0wKAAAAoAtKCgAAAKALa+Z0DwAAAFhLdv/x+8aOkCR58PNOXvG+SgoAVrVT3vWSsSMkSS479bVjRwAAWPWc7gEAAAB0QUkBAAAAdEFJAQAAAHRBSQEAAAB0QUkBAAAAdEFJAQAAAHRBSQEAAAB0Yd3YAQCm6c/e8vixI+QXf+7ysSMAAMCqpKQAAFjjTr3kyrEj5F2nnTh2BAA6oKQAAABYA279wzvGjpBNL3zI2BHonGtSAAAAAF1QUgAAAABdUFIAAAAAXVBSAAAAAF1QUgAAAABdUFIAAAAAXVBSAAAAAF1QUgAAAABdWDd2AACgH094x7ljR8hf/szWsSMAACMxkwIAAADogpICAAAA6IKSAgAAAOiCkgIAAADogpICAAAA6IKSAgAAAOiCkgIAAADogpICAAAA6IKSAgAAAOiCkgIAAADogpICAAAA6IKSAgAAAOiCkgIAAADowrpZPXFVnZ/kiUl2t9YeOYwdnuTiJJuS3Jrkaa21u6qqkrw+ySlJvpbkWa2164bvOSPJbwxP+3uttQtnlRlgXl5x8ePHjpCX/ezlY0cAAIB7mFlJkeRNSf44yZsXjJ2d5MrW2iur6uxh/deSnJzkmOHxQ0nOSfJDQ6nx8iSbk7Qk11bVttbaXTPMPZo7z3n12BGSJEc+51fGjgAAAMAaNLPTPVprH07ypX2GtyTZOxPiwiSnLhh/c5u4KsmhVfXQJI9PckVr7UtDMXFFkpNmlRkAAAAYz7yvSXFka+32YfmOJEcOyxuS3LZgv53D2FLjAAAAwAFmtAtnttZaJqdwTEVVba2q7VW1fc+ePdN6WgAAAGBO5l1S3DmcxpHh6+5hfFeSoxbst3EYW2r827TWzm2tbW6tbV6/fv3UgwMAAACzNe+SYluSM4blM5K8e8H4z9fECUm+MpwWcnmSx1XVYVV1WJLHDWMAAADAAWaWtyB9a5KfTHJEVe3M5C4dr0zy9qo6K8nnkjxt2P2yTG4/uiOTW5CemSSttS9V1e8muWbY73daa/tejBMAAAA4AMyspGitPX2JTScusm9L8twlnuf8JOdPMRoAAADQodEunAkAAACwkJICAAAA6IKSAgAAAOiCkgIAAADogpICAAAA6IKSAgAAAOiCkgIAAADogpICAAAA6MK6sQPAWnf5eaeMHSFJ8vizLhs7AgAAsMaZSQEAAAB0QUkBAAAAdEFJAQAAAHRBSQEAAAB0QUkBAAAAdEFJAQAAAHRBSQEAAAB0QUkBAAAAdEFJAQAAAHRBSQEAAAB0QUkBAAAAdEFJAQAAAHRBSQEAAAB0QUkBAAAAdEFJAQAAAHRBSQEAAAB0QUkBAAAAdEFJAQAAAHRBSQEAAAB0QUkBAAAAdEFJAQAAAHRBSQEAAAB0QUkBAAAAdEFJAQAAAHRBSQEAAAB0QUkBAAAAdEFJAQAAAHRBSQEAAAB0QUkBAAAAdEFJAQAAAHRBSQEAAAB0QUkBAAAAdEFJAQAAAHRBSQEAAAB0QUkBAAAAdEFJAQAAAHRBSQEAAAB0QUkBAAAAdEFJAQAAAHRBSQEAAAB0QUkBAAAAdEFJAQAAAHRBSQEAAAB0QUkBAAAAdEFJAQAAAHRBSQEAAAB0YZSSoqpeVFU3VtUNVfXWqrpvVR1dVVdX1Y6quriqDh72vc+wvmPYvmmMzAAAAMBszb2kqKoNSZ6fZHNr7ZFJDkpyepJXJXlda+27k9yV5KzhW85Kctcw/rphPwAAAOAAM9bpHuuS3K+q1iW5f5Lbkzw2ySXD9guTnDosbxnWM2w/sapqjlkBAACAOZh7SdFa25XkNUk+n0k58ZUk1yb5cmvt7mG3nUk2DMsbktw2fO/dw/4PmmdmAAAAYPbGON3jsExmRxyd5GFJDkly0hSed2tVba+q7Xv27PmPPh0AAAAwZ2Oc7vFTST7bWtvTWvvnJO9M8pgkhw6nfyTJxiS7huVdSY5KkmH7A5N8cd8nba2d21rb3FrbvH79+ln/NwAAAABTNkZJ8fkkJ1TV/YdrS5yY5KYkH0xy2rDPGUnePSxvG9YzbP9Aa63NMS8AAAAwB2Nck+LqTC6AeV2STwwZzk3ya0leXFU7MrnmxHnDt5yX5EHD+IuTnD3vzAAAAMDsrdv/LtPXWnt5kpfvM/yZJMcvsu8/JXnqPHIBAAAA4xnrFqQAAAAA96CkAAAAALqgpAAAAAC6oKQAAAAAuqCkAAAAALqgpAAAAAC6oKQAAAAAuqCkAAAAALqgpAAAAAC6oKQAAAAAuqCkAAAAALqgpAAAAAC6oKQAAAAAuqCkAAAAALqgpAAAAAC6oKQAAAAAuqCkAAAAALqgpAAAAAC6oKQAAAAAuqCkAAAAALqgpAAAAAC6oKQAAAAAurCikqKqrlzJGAAAAMC/17rlNlbVfZPcP8kRVXVYkho2PSDJhhlnAwAAANaQZUuKJL+Y5IVJHpbk2vxrSfHVJH88w1wAAADAGrNsSdFae32S11fVL7fW/mhOmQAAAIA1aH8zKZIkrbU/qqofSbJp4fe01t48o1wAAADAGrOikqKq3pLku5Jcn+RfhuGWREkBAAAATMWKSookm5Mc21prswwDAAAArF0rugVpkhuSPGSWQQAAAIC1baUzKY5IclNVfSTJ1/cOttaeNJNUAAAAwJqz0pLit2YZAgAAAGCld/f4m1kHAQAAANa2ld7d4x8yuZtHkhyc5N5J/rG19oBZBQMAAADWlpXOpPjOvctVVUm2JDlhVqEAAACAtWeld/f4ljbxriSPn0EeAAAAYI1a6ekeT1mweq8km5P800wSAQAAAGvSSu/u8dMLlu9Ocmsmp3wAAAAATMVKr0lx5qyDAAAAAGvbiq5JUVUbq+rSqto9PN5RVRtnHQ4AAABYO1Z64cwLkmxL8rDh8Z5hDAAAAGAqVlpSrG+tXdBau3t4vCnJ+hnmAgAAANaYlZYUX6yqZ1bVQcPjmUm+OMtgAAAAwNqy0pLi2UmeluSOJLcnOS3Js2aUCQAAAFiDVnoL0t9JckZr7a4kqarDk7wmk/ICAAAA4D9spTMpvm9vQZEkrbUvJXn0bCIBAAAAa9FKS4p7VdVhe1eGmRQrnYUBAAAAsF8rLRpem+Rvq+ovhvWnJnnFbCIBAAAAa9GKSorW2puranuSxw5DT2mt3TS7WAAAAMBas+JTNoZSQjEBAAAAzMRKr0kBAAAAMFNKCgAAAKALSgoAAACgC0oKAAAAoAtKCgAAAKALo5QUVXVoVV1SVbdU1c1V9cNVdXhVXVFVnx6+HjbsW1X1hqraUVUfr6rjxsgMAAAAzNZYMylen+SvWmvfm+T7k9yc5OwkV7bWjkly5bCeJCcnOWZ4bE1yzvzjAgAAALM295Kiqh6Y5MeTnJckrbVvtNa+nGRLkguH3S5McuqwvCXJm9vEVUkOraqHzjk2AAAAMGNjzKQ4OsmeJBdU1Uer6o1VdUiSI1trtw/73JHkyGF5Q5LbFnz/zmEMAAAAOICMUVKsS3JcknNaa49O8o/511M7kiSttZak/VuetKq2VtX2qtq+Z8+eqYUFAAAA5mOMkmJnkp2ttauH9UsyKS3u3Hsax/B197B9V5KjFnz/xmHsHlpr57bWNrfWNq9fv35m4QEAAIDZmHtJ0Vq7I8ltVfWIYejEJDcl2ZbkjGHsjCTvHpa3Jfn54S4fJyT5yoLTQgAAAIADxLqR/txfTnJRVR2c5DNJzsykMHl7VZ2V5HNJnjbse1mSU5LsSPK1YV8AAADgADNKSdFauz7J5kU2nbjIvi3Jc2ceCgAAABjVGNekAAAAAPg2SgoAAACgC0oKAAAAoAtKCgAAAKALSgoAAACgC0oKAAAAoAtKCgAAAKALSgoAAACgC0oKAAAAoAtKCgAAAKALSgoAAACgC0oKAAAAoAtKCgAAAKALSgoAAACgC0oKAAAAoAtKCgAAAKALSgoAAACgC0oKAAAAoAtKCgAAAKALSgoAAACgC0oKAAAAoAtKCgAAAKALSgoAAACgC0oKAAAAoAtKCgAAAKALSgoAAACgC0oKAAAAoAtKCgAAAKALSgoAAACgC0oKAAAAoAtKCgAAAKALSgoAAACgC0oKAAAAoAtKCgAAAKALSgoAAACgC0oKAAAAoAtKCgAAAKALSgoAAACgC0oKAAAAoAtKCgAAAKALSgoAAACgC0oKAAAAoAtKCgAAAKALSgoAAACgC0oKAAAAoAtKCgAAAKALSgoAAACgC0oKAAAAoAtKCgAAAKALSgoAAACgC0oKAAAAoAtKCgAAAKALSgoAAACgC0oKAAAAoAtKCgAAAKALo5UUVXVQVX20qt47rB9dVVdX1Y6quriqDh7G7zOs7xi2bxorMwAAADA7Y86keEGSmxesvyrJ61pr353kriRnDeNnJblrGH/dsB8AAABwgBmlpKiqjUmekOSNw3oleWySS4ZdLkxy6rC8ZVjPsP3EYX8AAADgADLWTIo/TPKrSb45rD8oyZdba3cP6zuTbBiWNyS5LUmG7V8Z9gcAAAAOIHMvKarqiUl2t9aunfLzbq2q7VW1fc+ePdN8agAAAGAOxphJ8ZgkT6qqW5O8LZPTPF6f5NCqWjfsszHJrmF5V5KjkmTY/sAkX9z3SVtr57bWNrfWNq9fv362/wUAAADA1M29pGitvbS1trG1tinJ6Uk+0Fp7RpIPJjlt2O2MJO8elrcN6xm2f6C11uYYGQAAAJiDMe/usa9fS/LiqtqRyTUnzhvGz0vyoGH8xUnOHikfAAAAMEPr9r/L7LTWPpTkQ8PyZ5Icv8g+/5TkqXMNBgAAAMxdTzMpAAAAgDVMSQEAAAB0QUkBAAAAdEFJAQAAAHRBSQEAAAB0QUkBAAAAdEFJAQAAAHRBSQEAAAB0QUkBAAAAdEFJAQAAAHRBSQEAAAB0QUkBAAAAdEFJAQAAAHRBSQEAAAB0QUkBAAAAdEFJAQAAAHRBSQEAAAB0QUkBAAAAdEFJAQAAAHRBSQEAAAB0QUkBAAAAdEFJAQAAAHRBSQEAAAB0QUkBAAAAdEFJAQAAAHRBSQEAAAB0QUkBAAAAdEFJAQAAAHRBSQEAAAB0QUkBAAAAdEFJAQAAAHRBSQEAAAB0QUkBAAAAdEFJAQAAAHRBSQEAAAB0QUkBAAAAdEFJAQAAAHRBSQEAAAB0QUkBAAAAdEFJAQAAAHRBSQEAAAB0QUkBAAAAdEFJAQAAAHRBSQEAAAB0QUkBAAAAdEFJAQAAAHRBSQEAAAB0QUkBAAAAdEFJAQAAAHRBSQEAAAB0QUkBAAAAdEFJAQAAAHRBSQEAAAB0QUkBAAAAdEFJAQAAAHRh7iVFVR1VVR+sqpuq6saqesEwfnhVXVFVnx6+HjaMV1W9oap2VNXHq+q4eWcGAAAAZm+MmRR3J3lJa+3YJCckeW5VHZvk7CRXttaOSXLlsJ4kJyc5ZnhsTXLO/CMDAAAAszb3kqK1dntr7bph+R+S3JxkQ5ItSS4cdrswyanD8pYkb24TVyU5tKoeOufYAAAAwIyNek2KqtqU5NFJrk5yZGvt9mHTHUmOHJY3JLltwbftHMYAAACAA8hoJUVVfUeSdyR5YWvtqwu3tdZakvZvfL6tVbW9qrbv2bNnikkBAACAeRilpKiqe2dSUFzUWnvnMHzn3tM4hq+7h/FdSY5a8O0bh7F7aK2d21rb3FrbvH79+tmFBwAAAGZijLt7VJLzktzcWvuDBZu2JTljWD4jybsXjP/8cJePE5J8ZcFpIQAAAMABYt0If+Zjkvxckk9U1fXD2K8neWWSt1fVWUk+l+Rpw7bLkpySZEeSryU5c75xAQAAgHmYe0nRWvu/SWqJzScusn9L8tyZhgIAAABGN+rdPQAAAAD2UlIAAAAAXVBSAAAAAF1QUgAAAABdUFIAAAAAXVBSAAAAAF1QUgAAAABdUFIAAAAAXVBSAAAAAF1QUgAAAABdUFIAAAAAXVBSAAAAAF1QUgAAAABdUFIAAAAAXVBSAAAAAF1QUgAAAABdUFIAAAAAXVBSAAAAAF1QUgAAAABdUFIAAAAAXVBSAAAAAF1QUgAAAABdUFIAAAAAXVBSAAAAAF1QUgAAAABdUFIAAAAAXVBSAAAAAF1QUgAAAABdUFIAAAAAXVBSAAAAAF1QUgAAAABdUFIAAAAAXVBSAAAAAF1QUgAAAABdUFIAAAAAXVBSAAAAAF1QUgAAAABdUFIAAAAAXVBSAAAAAF1QUgAAAABdUFIAAAAAXVBSAAAAAF1QUgAAAABdUFIAAAAAXVBSAAAAAF1QUgAAAABdUFIAAAAAXVBSAAAAAF1QUgAAAABdUFIAAAAAXVBSAAAAAF1QUgAAAABdUFIAAAAAXVBSAAAAAF1QUgAAAABdWDUlRVWdVFWfrKodVXX22HkAAACA6VoVJUVVHZTkT5KcnOTYJE+vqmPHTQUAAABM06ooKZIcn2RHa+0zrbVvJHlbki0jZwIAAACmaLWUFBuS3LZgfecwBgAAABwgqrU2dob9qqrTkpzUWvuFYf3nkvxQa+15C/bZmmTrsPqIJJ+ccowjknxhys85C3JOl5zTtRpyroaMiZzTJud0yTk9qyFjIue0yTldck7PasiYyDlts8j5n1pr6xfbsG7Kf9Cs7Epy1IL1jcPYt7TWzk1y7qwCVNX21trmWT3/tMg5XXJO12rIuRoyJnJOm5zTJef0rIaMiZzTJud0yTk9qyFjIue0zTvnajnd45okx1TV0VV1cJLTk2wbORMAAAAwRatiJkVr7e6qel6Sy5MclOT81tqNI8cCAAAApmhVlBRJ0lq7LMllI0aY2akkUybndMk5Xash52rImMg5bXJOl5zTsxoyJnJOm5zTJef0rIaMiZzTNtecq+LCmQAAAMCBb7VckwIAAAA4wCkpVqCqTqqqT1bVjqo6e+w8i6mq86tqd1XdMHaW5VTVUVX1waq6qapurKoXjJ1pMVV136r6SFV9bMj522NnWkpVHVRVH62q946dZSlVdWtVfaKqrq+q7WPnWUpVHVpVl1TVLVV1c1X98NiZ9lVVjxhex72Pr1bVC8fOtZiqetHw83NDVb21qu47dqZk8ffLqjq8qq6oqk8PXw8bM+OQabGcTx1e029W1ehXA18i46uHn6GPV9WlVXXomBmHTIvl/N0h4/VV9f6qetiYGYdMSx7Lq+olVdWq6ogxsu2TZbHX87eqateC96ZTxsw4ZFr09ayqXx7+jt5YVb8/Vr4FeRZ7PS9e8FreWlXXj5lxyLRYzkdV1VV7j+9VdXyHGb+/qv52+Bzynqp6wJgZh0yLfh7u7Vi0TM7ejkVL5ezqeLRMzm6OR0tlXLB9Psei1prHMo9MLtT5d0n+c5KDk3wsybFj51ok548nOS7JDWNn2U/OhyY5blj+ziSf6vT1rCTfMSzfO8nVSU4YO9cSWV+c5P8kee/YWZbJeGuSI8bOsYKcFyb5hWH54CSHjp1pP3kPSnJHJveZHj3PPtk2JPlskvsN629P8qyxcw1Zvu39MsnvJzl7WD47yas6zflfkjwiyYeSbO404+OSrBuWX9Xxa/mABcvPT/KnPeYcxo/K5OLhn+vhvXSJ1/O3kvzPsbOtIOd/S/LXSe4zrD+4x5z7bH9tkt/sMWeS9yc5eVg+JcmHOsx4TZKfGJafneR3O3gtF/083NuxaJmcvR2LlsrZ1fFomZzdHI+Wyjisz+1YZCbF/h2fZEdr7TOttW8keVuSLSNn+jattQ8n+dLYOfantXZ7a+26YfkfktycyT9mutIm/t+weu/h0d0FXKpqY5InJHnj2FlWu6p6YCYfbs5LktbaN1prXx431X6dmOTvWmufGzvIEtYluV9VrUty/yR/P3KeJEu+X27JpKTK8PXUuYZaxGI5W2s3t9Y+OVKkb7NExve31u4eVq9KsnHuwfaxRM6vLlg9JB28xy9zLH9dkl9NBxmTVfWZY7Gcz0nyytba14d9ds892D6Wez2rqpI8Lclb5xpqEUvkbEn2zkx4YEZ+n18i4/ck+fCwfEWSn5lrqEUs83m4q2PRUjk7PBYtlbOr49EyObs5Hu3n32pzOxYpKfZvQ5LbFqzvTIf/qF6NqmpTkkdnMkuhOzU5jeL6JLuTXNFa6zHnH2byZvHNsYPsR0vy/qq6tqq2jh1mCUcn2ZPkgpqcPvPGqjpk7FD7cXo6+OC6mNbariSvSfL5JLcn+Upr7f3jplrWka2124flO5IcOWaYA8izk7xv7BBLqapXVNVtSZ6R5DfHzrOYqtqSZFdr7WNjZ1mB5w1Tls8fe5r6Mr4nyY9V1dVV9TdV9YNjB9qPH0tyZ2vt02MHWcILk7x6+Dl6TZKXjpxnMTfmX3/B+NRMfhvcjX0+D3d7LOr9c/tey+Ts6ni0b84ej0cLM877WKSkYBRV9R1J3pHkhfu0h91orf1La+1RmbSux1fVI8fOtFBVPTHJ7tbatWNnWYEfba0dl+TkJM+tqh8fO9Ai1mUyRfSc1tqjk/xjJlMtu1RVByd5UpK/GDvLYoZ/oGzJpPx5WJJDquqZ46ZamTaZ09jFb6xXs6p6WZK7k1w0dpaltNZe1lo7KpOMzxs7z76q6v5Jfj2dfGDdj3OSfFeSR2VSTL523DhLWpfk8CQnJPmVJG8fZiv06unptIwePCfJi4afoxdlmI3YmWcn+R9VdW0m09e/MXKeb1nu83BPx6LV8Lk9WTpnb8ejxXL2djxamDGT126uxyIlxf7tyj0b143DGP9OVXXvTP7SX9Rae+fYefZnmPL/wSQnjZ1lH49J8qSqujWT05AeW1V/Pm6kxQ2/Vd87rfbSTE6j6s3OJDsXzJi5JJPSolcnJ7mutXbn2EGW8FNJPtta29Na++ck70zyIyNnWs6dVfXQJBm+jj4FfDWrqmcleWKSZwwftHt3UTqYAr6I78qk6PvY8F6/Mcl1VfWQUVMtorV251DufzPJ/06f7/PJ5L3+ncNpnR/JZCbi6BcjXcxwqtxTklw8dpZlnJHJ+3syKc27+//eWrultfa41toPZFL4/N3YmZIlPw93dyxaLZ/bl8rZ2/FoBa/n6MejRTLO/VikpNi/a5IcU1VHD7+5PD3JtpEzrVrDbyvOS3Jza+0Pxs6zlKpav/cKwFV1vyT/Pebe2ZQAAAJJSURBVMkt46a6p9baS1trG1trmzL5e/mB1lp3v6muqkOq6jv3LmdyEaPu7kLTWrsjyW1V9Yhh6MQkN40YaX96/+3a55OcUFX3H37uT8zkvMZebcvkw3aGr+8eMcuqVlUnZXIa2pNaa18bO89SquqYBatb0tl7fJK01j7RWntwa23T8F6/M5MLmt0xcrRvs/cfVoMnp8P3+cG7Mrl4ZqrqezK5SPIXRk20tJ9KcktrbefYQZbx90l+Ylh+bJLuTkupqgcPX++V5DeS/Om4iZb9PNzVsWgVfW5fNGdvx6NlcnZzPFos4yjHojby1VhXwyOTqxV/KpPm9WVj51ki41szmV75z8NfnLPGzrREzh/NZOrax5NcPzxOGTvXIjm/L8lHh5w3pIOrau8n70+m07t7ZHJnnI8Njxt7/Rkasj4qyfbh//u7khw2dqYlch6S5ItJHjh2lv3k/O1MDrQ3JHlLhqvpj/1Y7P0yyYOSXJnJB+y/TnJ4pzmfPCx/PcmdSS7vMOOOTK7ltPc9voe7ZiyW8x3D382PJ3lPJhcv6y7nPttvTR9391js9XxLkk8Mr+e2JA/tNOfBSf58+H9/XZLH9phzGH9Tkl8aO99+Xs8fTXLtcIy/OskPdJjxBZl8jv9UklcmqQ5ey0U/D/d2LFomZ2/HoqVydnU8WiZnN8ejpTLus8/Mj0U1/EEAAAAAo3K6BwAAANAFJQUAAADQBSUFAAAA0AUlBQAAANAFJQUAAADQBSUFAAAA0AUlBQAAANAFJQUAAADQhf8PHvP1WEUghc8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1296x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (18,8))\n",
    "sns.countplot(x =labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_binrizer = LabelBinarizer()\n",
    "labels = label_binrizer.fit_transform(labels)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('label', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = train.values\n",
    "images =  images/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size = 0.3, stratify = labels, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19218, 28, 28, 1), (8237, 28, 28, 1))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import GlobalMaxPooling2D, Dense, Conv2D, MaxPooling2D, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 24\n",
    "batch_size = 125\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hd16547/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 64)        1088      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        65600     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 5, 5, 64)          36928     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 24)                3096      \n",
      "=================================================================\n",
      "Total params: 139,608\n",
      "Trainable params: 139,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(4,4), activation = 'relu', input_shape=(28, 28 ,1), padding='same' ))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (4, 4), activation = 'relu', padding='same' ))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dense(num_classes, activation = 'softmax'))\n",
    "model.compile(loss = keras.losses.categorical_crossentropy, optimizer='nadam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    shear_range = 0.25,\n",
    "    zoom_range = 0.15,\n",
    "    rotation_range = 15,\n",
    "    brightness_range = [0.15, 1.15],\n",
    "    width_shift_range = [-2,-1, 0, +1, +2],\n",
    "    height_shift_range = [ -1, 0, +1],\n",
    "    fill_mode = 'reflect'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hd16547/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 19218 samples, validate on 8237 samples\n",
      "Epoch 1/50\n",
      "19218/19218 [==============================] - 13s 698us/step - loss: 2.0454 - accuracy: 0.3663 - val_loss: 1.2921 - val_accuracy: 0.7773\n",
      "Epoch 2/50\n",
      "19218/19218 [==============================] - 13s 683us/step - loss: 0.5098 - accuracy: 0.8268 - val_loss: 0.6050 - val_accuracy: 0.9604\n",
      "Epoch 3/50\n",
      "19218/19218 [==============================] - 13s 688us/step - loss: 0.2245 - accuracy: 0.9231 - val_loss: 0.3113 - val_accuracy: 0.9920\n",
      "Epoch 4/50\n",
      "19218/19218 [==============================] - 13s 681us/step - loss: 0.1149 - accuracy: 0.9615 - val_loss: 0.1726 - val_accuracy: 0.9978\n",
      "Epoch 5/50\n",
      "19218/19218 [==============================] - 13s 685us/step - loss: 0.0802 - accuracy: 0.9727 - val_loss: 0.1287 - val_accuracy: 0.9992\n",
      "Epoch 6/50\n",
      "19218/19218 [==============================] - 13s 684us/step - loss: 0.0607 - accuracy: 0.9788 - val_loss: 0.0743 - val_accuracy: 0.9994\n",
      "Epoch 7/50\n",
      "19218/19218 [==============================] - 13s 694us/step - loss: 0.0493 - accuracy: 0.9823 - val_loss: 0.0783 - val_accuracy: 0.9999\n",
      "Epoch 8/50\n",
      "19218/19218 [==============================] - 14s 704us/step - loss: 0.0400 - accuracy: 0.9858 - val_loss: 0.0473 - val_accuracy: 0.9999\n",
      "Epoch 9/50\n",
      "19218/19218 [==============================] - 13s 701us/step - loss: 0.0349 - accuracy: 0.9883 - val_loss: 0.0473 - val_accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "19218/19218 [==============================] - 13s 702us/step - loss: 0.0367 - accuracy: 0.9882 - val_loss: 0.0530 - val_accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "19218/19218 [==============================] - 13s 683us/step - loss: 0.0334 - accuracy: 0.9892 - val_loss: 0.0322 - val_accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "19218/19218 [==============================] - 13s 680us/step - loss: 0.0274 - accuracy: 0.9911 - val_loss: 0.0320 - val_accuracy: 0.9999\n",
      "Epoch 13/50\n",
      "19218/19218 [==============================] - 14s 713us/step - loss: 0.0290 - accuracy: 0.9908 - val_loss: 0.0395 - val_accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "19218/19218 [==============================] - 15s 783us/step - loss: 0.0290 - accuracy: 0.9911 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "19218/19218 [==============================] - 14s 714us/step - loss: 0.0255 - accuracy: 0.9909 - val_loss: 0.0470 - val_accuracy: 0.9975\n",
      "Epoch 16/50\n",
      "19218/19218 [==============================] - 14s 740us/step - loss: 0.0245 - accuracy: 0.9924 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "19218/19218 [==============================] - 15s 800us/step - loss: 0.0295 - accuracy: 0.9894 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "19218/19218 [==============================] - 13s 688us/step - loss: 0.0230 - accuracy: 0.9926 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "19218/19218 [==============================] - 13s 700us/step - loss: 0.0302 - accuracy: 0.9901 - val_loss: 0.0221 - val_accuracy: 0.9990\n",
      "Epoch 20/50\n",
      "19218/19218 [==============================] - 15s 777us/step - loss: 0.0203 - accuracy: 0.9937 - val_loss: 0.0245 - val_accuracy: 0.9990\n",
      "Epoch 21/50\n",
      "19218/19218 [==============================] - 14s 714us/step - loss: 0.0214 - accuracy: 0.9931 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "19218/19218 [==============================] - 14s 717us/step - loss: 0.0267 - accuracy: 0.9913 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "19218/19218 [==============================] - 13s 685us/step - loss: 0.0258 - accuracy: 0.9916 - val_loss: 0.0097 - val_accuracy: 0.9996\n",
      "Epoch 24/50\n",
      "19218/19218 [==============================] - 14s 746us/step - loss: 0.0270 - accuracy: 0.9912 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "19218/19218 [==============================] - 13s 698us/step - loss: 0.0276 - accuracy: 0.9915 - val_loss: 0.0108 - val_accuracy: 0.9994\n",
      "Epoch 26/50\n",
      "19218/19218 [==============================] - 14s 736us/step - loss: 0.0237 - accuracy: 0.9920 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "19218/19218 [==============================] - 13s 688us/step - loss: 0.0264 - accuracy: 0.9914 - val_loss: 0.0116 - val_accuracy: 0.9999\n",
      "Epoch 28/50\n",
      "19218/19218 [==============================] - 13s 680us/step - loss: 0.0261 - accuracy: 0.9915 - val_loss: 0.0077 - val_accuracy: 0.9994\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-fcc2eda9bfa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input size must be at least 32x32; got `input_shape=(28, 28, 3)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-aa5fdecce3c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpre_trained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"imagenet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/applications/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'utils'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbase_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/applications/vgg16.py\u001b[0m in \u001b[0;36mVGG16\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mkeras_modules_injection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mvgg16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras_applications/vgg16.py\u001b[0m in \u001b[0;36mVGG16\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m                                       \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                                       \u001b[0mrequire_flatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                                       weights=weights)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras_applications/imagenet_utils.py\u001b[0m in \u001b[0;36m_obtain_input_shape\u001b[0;34m(input_shape, default_size, min_size, data_format, require_flatten, weights)\u001b[0m\n\u001b[1;32m    320\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'x'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                                      \u001b[0;34m'; got `input_shape='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m                                      str(input_shape) + '`')\n\u001b[0m\u001b[1;32m    323\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrequire_flatten\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input size must be at least 32x32; got `input_shape=(28, 28, 3)`"
     ]
    }
   ],
   "source": [
    "pre_trained_model = VGG16(input_shape=(28,28,3), include_top=False, weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hd16547/.local/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_4 (Glob (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 14,977,857\n",
      "Trainable params: 7,342,593\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for layer in pre_trained_model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in pre_trained_model.layers[15:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "last_layer = pre_trained_model.get_layer('block5_pool')\n",
    "last_output = last_layer.output\n",
    "    \n",
    "\n",
    "x = GlobalMaxPooling2D()(last_output)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(pre_trained_model.input, x)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_1 to have shape (224, 224, 3) but got array with shape (28, 28, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-fcc2eda9bfa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_1 to have shape (224, 224, 3) but got array with shape (28, 28, 1)"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
